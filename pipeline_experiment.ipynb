{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - NLP\n",
    "\n",
    "## Grupo:\n",
    "- Laianna Lana Virginio da Silva - lvs2@cin.ufpe.br\n",
    "- Lucas Natan Correia Couri - lncc2@cin.ufpe.br\n",
    "- Mariama Celi Serafim de Oliveira - mcso@cin.ufpe.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "import load_files as lf\n",
    "import nlp_algorithms as nlp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcso\\AppData\\Local\\Temp/ipykernel_17376/2099918564.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url1_lang</th>\n",
       "      <th>url2_lang</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>ia_link1</th>\n",
       "      <th>ia_link2</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Time</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Style</th>\n",
       "      <th>Tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>https://www.washingtonpost.com/local/virginia-man-arrested-in-fatal-dui-crash-in-west-virginia/2020/01/01/740fbc7a-2cbe-11ea-bffe-020c88b3f120_story.html</td>\n",
       "      <td>https://www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html</td>\n",
       "      <td>https://web.archive.org/web/www.washingtonpost.com/local/virginia-man-arrested-in-fatal-dui-crash-in-west-virginia/2020/01/01/740fbc7a-2cbe-11ea-bffe-020c88b3f120_story.html</td>\n",
       "      <td>https://web.archive.org/web/www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>https://www.stlucianewsonline.com/guyana-three-injured-after-car-crashes-into-utility-pole/</td>\n",
       "      <td>https://www.thestar.com/news/world/europe/2020/01/01/fire-kills-animals-at-zoo-in-western-germany.html</td>\n",
       "      <td>https://web.archive.org/web/www.stlucianewsonline.com/guyana-three-injured-after-car-crashes-into-utility-pole/</td>\n",
       "      <td>https://web.archive.org/web/www.thestar.com/news/world/europe/2020/01/01/fire-kills-animals-at-zoo-in-western-germany.html</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>https://www.teaparty.org/trump-brings-in-2020-at-mar-a-lago-were-going-to-have-a-great-year-423052/</td>\n",
       "      <td>https://www.timesofisrael.com/trump-says-he-does-not-expect-war-with-iran-likes-peace/</td>\n",
       "      <td>https://web.archive.org/web/www.teaparty.org/trump-brings-in-2020-at-mar-a-lago-were-going-to-have-a-great-year-423052/</td>\n",
       "      <td>https://web.archive.org/web/www.timesofisrael.com/trump-says-he-does-not-expect-war-with-iran-likes-peace/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>https://gadgets.ndtv.com/apps/news/zomato-uber-eats-business-acquisition-india-all-stock-deal-2167155</td>\n",
       "      <td>https://gadgets.ndtv.com/internet/news/indian-online-food-delivery-market-to-hit-usd-8-billion-by-2020-google-bcg-report-2171043</td>\n",
       "      <td>https://web.archive.org/web/gadgets.ndtv.com/apps/news/zomato-uber-eats-business-acquisition-india-all-stock-deal-2167155</td>\n",
       "      <td>https://web.archive.org/web/gadgets.ndtv.com/internet/news/indian-online-food-delivery-market-to-hit-usd-8-billion-by-2020-google-bcg-report-2171043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>https://news.yahoo.com/india-approves-third-moon-mission-085759387.html</td>\n",
       "      <td>https://www.channelnewsasia.com/news/asia/india-targets-new-moon-mission-in-2020-12225344</td>\n",
       "      <td>https://web.archive.org/web/news.yahoo.com/india-approves-third-moon-mission-085759387.html</td>\n",
       "      <td>https://web.archive.org/web/www.channelnewsasia.com/news/asia/india-targets-new-moon-mission-in-2020-12225344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  url1_lang url2_lang                pair_id  \\\n",
       "0  en        en        1484084337_1484110209   \n",
       "1  en        en        1484396422_1483924666   \n",
       "2  en        en        1484698254_1483758694   \n",
       "3  en        en        1576314516_1576455088   \n",
       "4  en        en        1484036253_1483894099   \n",
       "\n",
       "                                                                                                                                                       link1  \\\n",
       "0  https://www.washingtonpost.com/local/virginia-man-arrested-in-fatal-dui-crash-in-west-virginia/2020/01/01/740fbc7a-2cbe-11ea-bffe-020c88b3f120_story.html   \n",
       "1  https://www.stlucianewsonline.com/guyana-three-injured-after-car-crashes-into-utility-pole/                                                                 \n",
       "2  https://www.teaparty.org/trump-brings-in-2020-at-mar-a-lago-were-going-to-have-a-great-year-423052/                                                         \n",
       "3  https://gadgets.ndtv.com/apps/news/zomato-uber-eats-business-acquisition-india-all-stock-deal-2167155                                                       \n",
       "4  https://news.yahoo.com/india-approves-third-moon-mission-085759387.html                                                                                     \n",
       "\n",
       "                                                                                                                                                                      link2  \\\n",
       "0  https://www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html   \n",
       "1  https://www.thestar.com/news/world/europe/2020/01/01/fire-kills-animals-at-zoo-in-western-germany.html                                                                     \n",
       "2  https://www.timesofisrael.com/trump-says-he-does-not-expect-war-with-iran-likes-peace/                                                                                     \n",
       "3  https://gadgets.ndtv.com/internet/news/indian-online-food-delivery-market-to-hit-usd-8-billion-by-2020-google-bcg-report-2171043                                           \n",
       "4  https://www.channelnewsasia.com/news/asia/india-targets-new-moon-mission-in-2020-12225344                                                                                  \n",
       "\n",
       "                                                                                                                                                                        ia_link1  \\\n",
       "0  https://web.archive.org/web/www.washingtonpost.com/local/virginia-man-arrested-in-fatal-dui-crash-in-west-virginia/2020/01/01/740fbc7a-2cbe-11ea-bffe-020c88b3f120_story.html   \n",
       "1  https://web.archive.org/web/www.stlucianewsonline.com/guyana-three-injured-after-car-crashes-into-utility-pole/                                                                 \n",
       "2  https://web.archive.org/web/www.teaparty.org/trump-brings-in-2020-at-mar-a-lago-were-going-to-have-a-great-year-423052/                                                         \n",
       "3  https://web.archive.org/web/gadgets.ndtv.com/apps/news/zomato-uber-eats-business-acquisition-india-all-stock-deal-2167155                                                       \n",
       "4  https://web.archive.org/web/news.yahoo.com/india-approves-third-moon-mission-085759387.html                                                                                     \n",
       "\n",
       "                                                                                                                                                                                       ia_link2  \\\n",
       "0  https://web.archive.org/web/www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html   \n",
       "1  https://web.archive.org/web/www.thestar.com/news/world/europe/2020/01/01/fire-kills-animals-at-zoo-in-western-germany.html                                                                     \n",
       "2  https://web.archive.org/web/www.timesofisrael.com/trump-says-he-does-not-expect-war-with-iran-likes-peace/                                                                                     \n",
       "3  https://web.archive.org/web/gadgets.ndtv.com/internet/news/indian-online-food-delivery-market-to-hit-usd-8-billion-by-2020-google-bcg-report-2171043                                           \n",
       "4  https://web.archive.org/web/www.channelnewsasia.com/news/asia/india-targets-new-moon-mission-in-2020-12225344                                                                                  \n",
       "\n",
       "   Geography  Entities      Time  Narrative   Overall     Style      Tone  \n",
       "0  4.0        4.000000  1.000000  4.000000   4.000000  1.666667  2.000000  \n",
       "1  4.0        4.000000  1.000000  4.000000   3.666667  1.666667  1.333333  \n",
       "2  1.0        2.000000  1.000000  2.333333   2.333333  1.000000  1.333333  \n",
       "3  1.0        2.333333  2.666667  1.666667   2.000000  1.666667  1.666667  \n",
       "4  1.0        1.250000  1.000000  1.250000   1.250000  1.000000  1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "## dfSourceV2 = pd.read_csv('../Dados/v2_semeval-2022_task8_train-data_batch.csv')\n",
    "train_v1 = pd.read_csv('dados/train v0.1.csv')\n",
    "\n",
    "train_v1_enen = train_v1[(train_v1['url1_lang'] == 'en') & (train_v1['url2_lang'] == 'en')]\n",
    "\n",
    "train_v1_enen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dados/train v0.1/'\n",
    "\n",
    "lista_docs = []\n",
    "lista_error = []\n",
    "lista_vazio = []\n",
    "values = train_v1_enen[['pair_id', 'Overall']]\n",
    "\n",
    "for index, values in values.iterrows():\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        json_pair = lf.get_json_document_pair(data_path, values['pair_id'])\n",
    "        text_doc1 = json_pair[0]['text']\n",
    "        text_doc2 = json_pair[1]['text']\n",
    "        \n",
    "        if ( len(text_doc1) > 0 ) and ( len(text_doc2) > 0 ):\n",
    "            lista_docs.append((values['pair_id'], text_doc1, text_doc2, values['Overall']))\n",
    "        else:\n",
    "            lista_vazio.append(values['pair_id'])\n",
    "    \n",
    "    except:\n",
    "        lista_error.append(values['pair_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(lista_docs,  columns=['pair_id', 'doc1', 'doc2', 'Overall'])\n",
    "#df_text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1357, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mcso\\Desktop\\residencia\\NLP\\projeto2-nlp-sidi-residencia\\preprocessing.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"doc1_pipeline{index}\"] = df[\"doc1\"].apply(lambda x: pre_process(x, **param))\n",
      "c:\\Users\\mcso\\Desktop\\residencia\\NLP\\projeto2-nlp-sidi-residencia\\preprocessing.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"doc2_pipeline{index}\"] = df[\"doc2\"].apply(lambda x: pre_process(x, **param))\n"
     ]
    }
   ],
   "source": [
    "pre_processing_list = [\n",
    "    {},\n",
    "    {\"basic_processing\": True},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True},\n",
    "    {\"basic_processing\": True, \"stemming\": True},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"stemming\": True},\n",
    "    {\"basic_processing\": True, \"lema\":  True},\n",
    "    {\"basic_processing\": True, \"no_stopwords\": True, \"lema\": True}]\n",
    "\n",
    "#df_pp = pp.pre_process_all(df_text, pre_processing_list)\n",
    "df_pp = pp.pre_process_all(df_text.iloc[:10], pre_processing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pp.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pair_id  Overall\n",
       "0  1484084337_1484110209  4.0    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = df_pp[[\"pair_id\", \"Overall\"]]\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = nlp.apply_bow(df_pp, len(pre_processing_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.join(df_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>Overall</th>\n",
       "      <th>bow0</th>\n",
       "      <th>bow1</th>\n",
       "      <th>bow2</th>\n",
       "      <th>bow3</th>\n",
       "      <th>bow4</th>\n",
       "      <th>bow5</th>\n",
       "      <th>bow6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.554412</td>\n",
       "      <td>0.568225</td>\n",
       "      <td>0.118185</td>\n",
       "      <td>0.567762</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.568225</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.658932</td>\n",
       "      <td>0.662808</td>\n",
       "      <td>0.077949</td>\n",
       "      <td>0.652465</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>0.658427</td>\n",
       "      <td>0.078285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.642877</td>\n",
       "      <td>0.652648</td>\n",
       "      <td>0.395561</td>\n",
       "      <td>0.658897</td>\n",
       "      <td>0.410352</td>\n",
       "      <td>0.689574</td>\n",
       "      <td>0.465636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.678074</td>\n",
       "      <td>0.683262</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.683147</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>0.684565</td>\n",
       "      <td>0.475937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.790918</td>\n",
       "      <td>0.780586</td>\n",
       "      <td>0.479421</td>\n",
       "      <td>0.799176</td>\n",
       "      <td>0.540089</td>\n",
       "      <td>0.799223</td>\n",
       "      <td>0.535830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pair_id   Overall      bow0      bow1      bow2      bow3  \\\n",
       "0  1484084337_1484110209  4.000000  0.554412  0.568225  0.118185  0.567762   \n",
       "1  1484396422_1483924666  3.666667  0.658932  0.662808  0.077949  0.652465   \n",
       "2  1484698254_1483758694  2.333333  0.642877  0.652648  0.395561  0.658897   \n",
       "3  1576314516_1576455088  2.000000  0.678074  0.683262  0.461996  0.683147   \n",
       "4  1484036253_1483894099  1.250000  0.790918  0.780586  0.479421  0.799176   \n",
       "\n",
       "       bow4      bow5      bow6  \n",
       "0  0.118088  0.568225  0.117200  \n",
       "1  0.078233  0.658427  0.078285  \n",
       "2  0.410352  0.689574  0.465636  \n",
       "3  0.482403  0.684565  0.475937  \n",
       "4  0.540089  0.799223  0.535830  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_idf = nlp.apply_tf_idf(df_pp, len(pre_processing_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.join(df_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>Overall</th>\n",
       "      <th>bow0</th>\n",
       "      <th>bow1</th>\n",
       "      <th>bow2</th>\n",
       "      <th>bow3</th>\n",
       "      <th>bow4</th>\n",
       "      <th>bow5</th>\n",
       "      <th>bow6</th>\n",
       "      <th>tf_idf0</th>\n",
       "      <th>tf_idf1</th>\n",
       "      <th>tf_idf2</th>\n",
       "      <th>tf_idf3</th>\n",
       "      <th>tf_idf4</th>\n",
       "      <th>tf_idf5</th>\n",
       "      <th>tf_idf6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1484084337_1484110209</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.554412</td>\n",
       "      <td>0.568225</td>\n",
       "      <td>0.118185</td>\n",
       "      <td>0.567762</td>\n",
       "      <td>0.118088</td>\n",
       "      <td>0.568225</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.204060</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.079230</td>\n",
       "      <td>0.220277</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>0.212621</td>\n",
       "      <td>0.075596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1484396422_1483924666</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.658932</td>\n",
       "      <td>0.662808</td>\n",
       "      <td>0.077949</td>\n",
       "      <td>0.652465</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>0.658427</td>\n",
       "      <td>0.078285</td>\n",
       "      <td>0.256470</td>\n",
       "      <td>0.253428</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.248462</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.249139</td>\n",
       "      <td>0.041451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1484698254_1483758694</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.642877</td>\n",
       "      <td>0.652648</td>\n",
       "      <td>0.395561</td>\n",
       "      <td>0.658897</td>\n",
       "      <td>0.410352</td>\n",
       "      <td>0.689574</td>\n",
       "      <td>0.465636</td>\n",
       "      <td>0.341090</td>\n",
       "      <td>0.353646</td>\n",
       "      <td>0.234897</td>\n",
       "      <td>0.370994</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>0.395499</td>\n",
       "      <td>0.280169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1576314516_1576455088</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.678074</td>\n",
       "      <td>0.683262</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.683147</td>\n",
       "      <td>0.482403</td>\n",
       "      <td>0.684565</td>\n",
       "      <td>0.475937</td>\n",
       "      <td>0.472555</td>\n",
       "      <td>0.466816</td>\n",
       "      <td>0.391316</td>\n",
       "      <td>0.485522</td>\n",
       "      <td>0.416267</td>\n",
       "      <td>0.470828</td>\n",
       "      <td>0.396233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484036253_1483894099</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.790918</td>\n",
       "      <td>0.780586</td>\n",
       "      <td>0.479421</td>\n",
       "      <td>0.799176</td>\n",
       "      <td>0.540089</td>\n",
       "      <td>0.799223</td>\n",
       "      <td>0.535830</td>\n",
       "      <td>0.570528</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.400790</td>\n",
       "      <td>0.592051</td>\n",
       "      <td>0.487107</td>\n",
       "      <td>0.582280</td>\n",
       "      <td>0.474820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pair_id   Overall      bow0      bow1      bow2      bow3  \\\n",
       "0  1484084337_1484110209  4.000000  0.554412  0.568225  0.118185  0.567762   \n",
       "1  1484396422_1483924666  3.666667  0.658932  0.662808  0.077949  0.652465   \n",
       "2  1484698254_1483758694  2.333333  0.642877  0.652648  0.395561  0.658897   \n",
       "3  1576314516_1576455088  2.000000  0.678074  0.683262  0.461996  0.683147   \n",
       "4  1484036253_1483894099  1.250000  0.790918  0.780586  0.479421  0.799176   \n",
       "\n",
       "       bow4      bow5      bow6   tf_idf0   tf_idf1   tf_idf2   tf_idf3  \\\n",
       "0  0.118088  0.568225  0.117200  0.204060  0.214436  0.079230  0.220277   \n",
       "1  0.078233  0.658427  0.078285  0.256470  0.253428  0.042134  0.248462   \n",
       "2  0.410352  0.689574  0.465636  0.341090  0.353646  0.234897  0.370994   \n",
       "3  0.482403  0.684565  0.475937  0.472555  0.466816  0.391316  0.485522   \n",
       "4  0.540089  0.799223  0.535830  0.570528  0.522019  0.400790  0.592051   \n",
       "\n",
       "    tf_idf4   tf_idf5   tf_idf6  \n",
       "0  0.074928  0.212621  0.075596  \n",
       "1  0.043084  0.249139  0.041451  \n",
       "2  0.256862  0.395499  0.280169  \n",
       "3  0.416267  0.470828  0.396233  \n",
       "4  0.487107  0.582280  0.474820  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#Inicializando o modelo\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def bert_cos(doc1, doc2):\n",
    "    data = [doc1,doc2]\n",
    "    sentence_embeddings = model.encode(data)\n",
    "\n",
    "    infer1 = sentence_embeddings[0]\n",
    "    infer2 =  sentence_embeddings[1]\n",
    "    #cos_distance = spatial.distance.cosine(infer1, infer2) #pode ser >1\n",
    "    cos_similarity = 1-spatial.distance.cosine(infer1, infer2) #de 0 a 1\n",
    "    return cos_similarity\n",
    "\n",
    "\n",
    "dfText['bert'] = dfText.apply(lambda row: bert_cos(\" \".join(row['no_stopwords1']), \" \".join(row['no_stopwords2'])), axis=1)\n",
    "\n",
    "dfText[[\"Overall\", \"bert\",\"doc2vec\"]].corr()\n",
    "\n",
    "sns.scatterplot(data=dfText, x=\"Overall\", y=\"bert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = join_unique_docs(dfText, 'msg_lemmatized1', 'msg_lemmatized2')\n",
    "data = join_docs(dfText, 'msg_lemmatized1', 'msg_lemmatized2', unique = True)\n",
    "\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=30, min_count=0, epochs=80)\n",
    "\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=80)\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "\n",
    "model = Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "def doc2vec_cos(doc1, doc2):\n",
    "    infer1 = model.infer_vector(doc1)\n",
    "    infer2 = model.infer_vector(doc2)\n",
    "    #cos_distance = spatial.distance.cosine(infer1, infer2) #pode ser >1\n",
    "    cos_similarity = 1-spatial.distance.cosine(infer1, infer2) #de 0 a 1\n",
    "    return cos_similarity\n",
    "\n",
    "\n",
    "dfText['doc2vec'] = dfText.apply(lambda row: doc2vec_cos(row['msg_tokenized1'], row['msg_tokenized2']), axis=1)\n",
    "\n",
    "dfText[['doc2vec', 'Overall']].head(20)\n",
    "\n",
    "dfText.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# print(api.load(\"word2vec-google-news-300\", return_path=True))\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "#model = KeyedVectors.load_word2vec_format('data/wiki.en.vec', binary=False)\n",
    "# model = KeyedVectors.load_word2vec_format('model/word2vec-google-news-300.gz', binary=True)\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "def get_mean_vector(word2vec_model, words): #words eh um documento inteiro\n",
    "    # remove out-of-vocabulary words\n",
    "    words = [word for word in words if word in model.index_to_key]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(word2vec_model[words], axis=0)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "get_mean_vector(model, dfText['no_stopwords1'][0])\n",
    "\n",
    "def word2vec_cos(doc1, doc2, model):\n",
    "    mean_doc1 = get_mean_vector(model, doc1)\n",
    "    mean_doc2 = get_mean_vector(model, doc2)\n",
    "\n",
    "    infer1 = mean_doc1\n",
    "    infer2 =  mean_doc2\n",
    "    #cos_distance = spatial.distance.cosine(infer1, infer2) #pode ser >1\n",
    "    cos_similarity = 1-spatial.distance.cosine(infer1, infer2) #de 0 a 1\n",
    "    return cos_similarity\n",
    "\n",
    "dfText['word2vec_mean'] = dfText.iloc[0:10].apply(lambda row: word2vec_cos(\" \".join(row['no_stopwords1']), \" \".join(row['no_stopwords2']), model), axis=1)\n",
    "\n",
    "dfText[['word2vec_mean', 'tfidf', 'Overall']].head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "578d23e9265697bad3ff07bcff4c72684a1087c3ecac6cf42decc0cb53b76ed7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
